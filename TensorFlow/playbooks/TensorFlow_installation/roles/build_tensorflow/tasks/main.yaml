---

# Before we gather information about AVX*, SSE*, FMA, etc. instructions, let's get the
# version of gcc
- name: Determine gcc version
  shell: '{{ CC }} --version | xargs | cut -d " " -f 3'
  register: GCC_VERSION

- name: Determine gcc main version
  shell: echo '{{ GCC_VERSION.stdout }}' | cut -d"." -f 1
  register: GCC_MAIN_VERSION

- name: Determine additional release info
  shell: echo '{{ GCC_VERSION.stdout }}' | cut -d"." -f 2
  register: GCC_RELEASE

# This is a workaround for determining which Ansible var will be used
- name: Determine whether the user specified AVX* instructions or if they want this playbook to optimize for them
  shell: |
    if [[ '{{ AVX_INSTRUCTIONS }}' != 'avx' ]] && [[ '{{ AVX_INSTRUCTIONS }}' != 'avx2' ]] && [[ '{{ AVX_INSTRUCTIONS }}' != 'avx512' ]]; then echo 'default'; else echo 'user_defined'; fi
  register: AVX_SETTINGS

# This is also a workaround for determining which Ansible var will be used
- name: Determine whether the user specified SSE* instructions or if they want this playbook to optimize for them
  shell: |
    if [[ '{{ SSE_INSTRUCTIONS }}' != 'sse2' ]] && [[ '{{ SSE_INSTRUCTIONS }}' != 'sse3' ]] && [[ '{{ SSE_INSTRUCTIONS }}' != 'sse4.1' ]] && [[ '{{ SSE_INSTRUCTIONS }}' != 'sse4.2' ]] ; then echo 'default'; else echo 'user_defined'; fi
  register: SSE_SETTINGS

# For users who want this playbook to determine the AVX instructions on their machine...
- block:

  # Next step is to determine if we have any AVX* instructions that we can take advantage of
  - name: Determine if we have AVX instructions
    shell: |
      avx=$(lscpu | grep 'Flags' | grep avx)
      echo $avx
    register: DEFAULT_HAVE_AVX

  - name: Determine if we have AVX2 instructions
    shell: |
      avx2=$(lscpu | grep 'Flags' | grep avx2)
      echo $avx2
    register: DEFAULT_HAVE_AVX2

  # XXX:TODO --> Make check to see which version of gcc is being used. TensorFlow requires
  # gcc version 4.9 or greater if using -mavx512f, -mavx512dq, etc.
  - name: Determine if we have AVX512F instructions
    shell: |
      avx512f=$(lscpu | grep 'Flags' | grep avx512f)
      echo $avx512f
    register: DEFAULT_HAVE_AVX512F

  - name: Determine if we have AVX512DQ instructions
    shell: |
      avx512dq=$(lscpu | grep 'Flags' | grep avx512dq)
      echo $avx512dq
    register: DEFAULT_HAVE_AVX512DQ

  - name: Determine if we have AVX512CD instructions
    shell: |
      avx512cd=$(lscpu | grep 'Flags' | grep avx512cd)
      echo $avx512cd
    register: DEFAULT_HAVE_AVX512CD

  # Next step is to determine if we have FMA instructions that we can take advantage of
  - name: Determine if we have FMA instructions
    shell: |
      fma=$(lscpu | grep 'Flags' | grep fma)
      echo $fma
    register: DEFAULT_HAVE_FMA

  # Now that we've gathered information on optimization flags, let's set them appropriately
  - name: Set FMA flag
    shell: if [[ ! -z '{{ DEFAULT_HAVE_FMA.stdout }}' ]]; then echo "--copt=-mfma"; else echo ""; fi
    register: DEFAULT_ENABLE_FMA

  - name: Set AVX copt flag
    shell: if [[ ! -z '{{ DEFAULT_HAVE_AVX.stdout }}' ]]; then echo "--copt=-mavx"; else echo ""; fi
    register: DEFAULT_ENABLE_AVX

  - name: Set AVX2 copt flag
    shell: if [[ ! -z '{{ DEFAULT_HAVE_AVX2.stdout }}' ]]; then echo "--copt=-mavx2"; else echo ""; fi
    register: DEFAULT_ENABLE_AVX2

  - name: Set AVX512 copt flag
    shell: if (( '{{ GCC_MAIN_VERSION.stdout }}' < '{{ TENSORFLOW_AVX512_MIN_GCC_VER }}' )); then echo ""; elif (( '{{ GCC_RELEASE.stdout }}' < '{{ TENSORFLOW_AVX512_MIN_GCC_REL }}' )) && (( '{{ GCC_MAIN_VERSION.stdout }}' == '{{ TENSORFLOW_AVX512_MIN_GCC_VER }}' )); then echo ""; elif [[ ! -z '{{ DEFAULT_HAVE_AVX512F.stdout }}' ]]; then echo "--copt=-mavx512f"; elif [[ ! -z '{{ DEFAULT_HAVE_AVX512DQ.stdout }}' ]]; then echo "--copt=-mavx512dq"; elif [[ ! -z '{{ DEFAULT_HAVE_AVX512CD.stdout }}' ]]; then echo "--copt=-mavx512cd"; else echo ""; fi
    register: DEFAULT_ENABLE_AVX512

  when: AVX_INSTRUCTIONS|length == 0


# If the user specified their AVX instructions...
- block:

  - name: Did the user specify AVX?
    shell: |
      echo 'avx'
    register: HAVE_AVX
    when: AVX_INSTRUCTIONS == 'avx' or AVX_INSTRUCTIONS == 'avx2' or AVX_INSTRUCTIONS == 'avx512'

  - name: Did the user specify AVX2?
    shell: |
      echo 'avx2'
    register: HAVE_AVX2
    when: AVX_INSTRUCTIONS == 'avx2' or AVX_INSTRUCTIONS == 'avx512'

  - name: If the user specified AVX512 instructions, determine if we have AVX512F instructions
    shell: |
      avx512f=$(lscpu | grep 'Flags' | grep avx512f)
      echo $avx512f
    register: HAVE_AVX512F
    when: AVX_INSTRUCTIONS == 'avx512'

  - name: If the user specified AVX512 instructions, determine if we have AVX512DQ instructions
    shell: |
      avx512dq=$(lscpu | grep 'Flags' | grep avx512dq)
      echo $avx512dq
    register: HAVE_AVX512DQ
    when: AVX_INSTRUCTIONS == 'avx512'

  - name: If the user specified AVX512 instructions, determine if we have AVX512CD instructions
    shell: |
      avx512cd=$(lscpu | grep 'Flags' | grep avx512cd)
      echo $avx512cd
    register: HAVE_AVX512CD
    when: AVX_INSTRUCTIONS == 'avx512'

  # Next step is to determine if we have FMA instructions that we can take advantage of
  - name: Determine if we have FMA instructions
    shell: |
      fma=$(lscpu | grep 'Flags' | grep fma)
      echo $fma
    register: HAVE_FMA

  # Now that we've gathered information on optimization flags, let's set them appropriately
  - name: Set FMA flag
    shell: if [[ ! -z '{{ HAVE_FMA.stdout }}' ]]; then echo "--copt=-mfma"; else echo ""; fi
    register: ENABLE_FMA

  # Now that we've gathered information on optimization flags, let's set them appropriately
  - name: Set AVX copt flag
    shell: if [[ ! -z '{{ HAVE_AVX.stdout }}' ]]; then echo "--copt=-mavx"; else echo ""; fi
    register: ENABLE_AVX

  - name: Set AVX2 copt flag
    shell: if [[ ! -z '{{ HAVE_AVX2.stdout }}' ]]; then echo "--copt=-mavx2"; else echo ""; fi
    register: ENABLE_AVX2

  - name: Set AVX512 copt flag
    shell: if (( '{{ GCC_MAIN_VERSION.stdout }}' < '{{ TENSORFLOW_AVX512_MIN_GCC_VER }}' )); then echo ""; elif (( '{{ GCC_RELEASE.stdout }}' < '{{ TENSORFLOW_AVX512_MIN_GCC_REL }}' )) && (( '{{ GCC_MAIN_VERSION.stdout }}' == '{{ TENSORFLOW_AVX512_MIN_GCC_VER }}' )); then echo ""; elif [[ ! -z '{{ HAVE_AVX512F.stdout }}' ]]; then echo "--copt=-mavx512f"; elif [[ ! -z '{{ HAVE_AVX512DQ.stdout }}' ]]; then echo "--copt=-mavx512dq"; elif [[ ! -z '{{ HAVE_AVX512CD.stdout }}' ]]; then echo "--copt=-mavx512cd"; else echo ""; fi
    register: ENABLE_AVX512

  when: AVX_INSTRUCTIONS|length > 0

# Now determine SSE* instructions
- block:

  - name: Determine if we have SSE2 instructions
    shell: |
      sse2=$(lscpu | grep 'Flags' | grep sse2)
      echo $sse2
    register: DEFAULT_HAVE_SSE2

  - name: Determine if we have SSE3 instructions
    shell: |
      sse3=$(lscpu | grep 'Flags' | grep sse3)
      echo $sse3
    register: DEFAULT_HAVE_SSE3

  - name: Determine if we have SSE4.1 instructions
    shell: |
      sse4_1=$(lscpu | grep 'Flags' | grep sse4_1)
      echo $sse4_1
    register: DEFAULT_HAVE_SSE4_1

  - name: Determine if we have SSE4.2 instructions
    shell: |
      sse4_2=$(lscpu | grep 'Flags' | grep sse4_2)
      echo $sse4_2
    register: DEFAULT_HAVE_SSE4_2

  - name: Set SSE2 copt flag
    shell: if [[ ! -z '{{ DEFAULT_HAVE_SSE2.stdout }}' ]]; then echo "--copt=-msse2"; else echo ""; fi
    register: DEFAULT_ENABLE_SSE2

  - name: Set SSE3 copt flag
    shell: if [[ ! -z '{{ DEFAULT_HAVE_SSE3.stdout }}' ]]; then echo "--copt=-msse3"; else echo ""; fi
    register: DEFAULT_ENABLE_SSE3

  - name: Set SSE4.1 copt flag
    shell: if [[ ! -z '{{ DEFAULT_HAVE_SSE4_1.stdout }}' ]]; then echo "--copt=-msse4.1"; else echo ""; fi
    register: DEFAULT_ENABLE_SSE4_1

  - name: Set SSE4.2 copt flag
    shell: if [[ ! -z '{{ DEFAULT_HAVE_SSE4_2.stdout }}' ]]; then echo "--copt=-msse4.2"; else echo ""; fi
    register: DEFAULT_ENABLE_SSE4_2

  when: SSE_INSTRUCTIONS|length == 0

- block:
  - name: Determine if we have SSE2 instructions
    shell: |
      sse2=$(lscpu | grep 'Flags' | grep sse2)
      if [[ ! -z $sse2 ]]; then echo 'sse2'; else echo ''; fi
    register: HAVE_SSE2
    when: SSE_INSTRUCTIONS == 'sse2' or SSE_INSTRUCTIONS == 'sse3' or SSE_INSTRUCTIONS == 'sse4.1' or SSE_INSTRUCTIONS == 'sse4.2'

  - name: Determine if we have SSE3 instructions
    shell: |
      sse3=$(lscpu | grep 'Flags' | grep sse3)
      if [[ ! -z $sse3 ]]; then echo 'sse3'; else echo ''; fi
    register: HAVE_SSE3
    when: SSE_INSTRUCTIONS == 'sse3' or SSE_INSTRUCTIONS == 'sse4.1' or SSE_INSTRUCTIONS == 'sse4.2'

  - name: Determine if we have SSE4.1 instructions
    shell: |
      sse4_1=$(lscpu | grep 'Flags' | grep sse4_1)
      if [[ ! -z $sse4_1 ]]; then echo 'sse4.1'; else echo ''; fi
    register: HAVE_SSE4_1
    when: SSE_INSTRUCTIONS == 'sse4.1' or SSE_INSTRUCTIONS == 'sse4.2'

  - name: Determine if we have SSE4.2 instructions
    shell: |
      sse4_2=$(lscpu | grep 'Flags' | grep sse4_2)
      if [[ ! -z $sse4_2 ]]; then echo 'sse4.2'; else echo ''; fi
    register: HAVE_SSE4_2
    when: SSE_INSTRUCTIONS == 'sse4.2'

  - name: Set SSE2 copt flag
    shell: if [[ ! -z '{{ HAVE_SSE2.stdout }}' ]]; then echo "--copt=-msse2"; else echo ""; fi
    register: ENABLE_SSE2

  - name: Set SSE3 copt flag
    shell: if [[ ! -z '{{ HAVE_SSE3.stdout }}' ]]; then echo "--copt=-msse3"; else echo ""; fi
    register: ENABLE_SSE3

  - name: Set SSE4.1 copt flag
    shell: if [[ ! -z '{{ HAVE_SSE4_1.stdout }}' ]]; then echo "--copt=-msse4.1"; else echo ""; fi
    register: ENABLE_SSE4_1

  - name: Set SSE4.2 copt flag
    shell: if [[ ! -z '{{ HAVE_SSE4_2.stdout }}' ]]; then echo "--copt=-msse4.2"; else echo ""; fi
    register: ENABLE_SSE4_2

  when: SSE_INSTRUCTIONS|length > 0

# Now let's print out our final compilation flags
- debug:
    msg: "Build flags: {{ DEFAULT_ENABLE_AVX.stdout }} {{ DEFAULT_ENABLE_AVX2.stdout }} {{ DEFAULT_ENABLE_AVX512.stdout }} {{ DEFAULT_ENABLE_FMA.stdout }} {{ ENABLE_SSE2.stdout }} {{ ENABLE_SSE3.stdout }} {{ ENABLE_SSE4_1.stdout }} {{ ENABLE_SSE4_2.stdout }}"
  when: AVX_SETTINGS.stdout == 'default' and SSE_SETTINGS.stdout == 'user_defined'

- debug:
    msg: "Build flags: {{ DEFAULT_ENABLE_AVX.stdout }} {{ DEFAULT_ENABLE_AVX2.stdout }} {{ DEFAULT_ENABLE_AVX512.stdout }} {{ DEFAULT_ENABLE_FMA.stdout }} {{ DEFAULT_ENABLE_SSE2.stdout }} {{ DEFAULT_ENABLE_SSE3.stdout }} {{ DEFAULT_ENABLE_SSE4_1.stdout }} {{ DEFAULT_ENABLE_SSE4_2.stdout }}"
  when: AVX_SETTINGS.stdout == 'default' and SSE_SETTINGS.stdout == 'default'

- debug:
    msg: "Build flags: {{ ENABLE_AVX.stdout }} {{ ENABLE_AVX2.stdout }} {{ ENABLE_AVX512.stdout }} {{ ENABLE_FMA.stdout }} {{ DEFAULT_ENABLE_SSE2.stdout }} {{ DEFAULT_ENABLE_SSE3.stdout }} {{ DEFAULT_ENABLE_SSE4_1.stdout }} {{ DEFAULT_ENABLE_SSE4_2.stdout }}"
  when: AVX_SETTINGS.stdout == 'user_defined' and SSE_SETTINGS.stdout == 'default'

- debug:
    msg: "Build flags: {{ ENABLE_AVX.stdout }} {{ ENABLE_AVX2.stdout }} {{ ENABLE_AVX512.stdout }} {{ ENABLE_FMA.stdout }} {{ ENABLE_SSE2.stdout }} {{ ENABLE_SSE3.stdout }} {{ ENABLE_SSE4_1.stdout }} {{ ENABLE_SSE4_2.stdout }}"
  when: AVX_SETTINGS.stdout == 'user_defined' and SSE_SETTINGS.stdout == 'user_defined'

- name: Determine main TensorFlow version
  shell: echo '{{ TENSORFLOW_VERSION }}' | cut -d '.' -f 1
  register: TF_MAIN_VERSION

- name: Determine TensorFlow release
  shell: echo '{{ TENSORFLOW_VERSION }}' | cut -d '.' -f 2
  register: TF_RELEASE

# Setup files for TF 2.1.0 and greater
- block:

  - name: Remove {{ TENSORFLOW_BUILD_DIR }}/third_party/py/BUILD because it's empty and useless right now
    file:
      state: absent
      path: '{{ TENSORFLOW_BUILD_DIR }}/third_party/py/BUILD'

  - name: Copy {{ TENSORFLOW_BUILD_DIR }}/third_party/toolchains/preconfig/ubuntu16.04/py/BUILD to {{ TENSORFLOW_BUILD_DIR }}/third_party/py/BUILD
    copy:
      src: '{{ TENSORFLOW_BUILD_DIR }}/third_party/toolchains/preconfig/ubuntu16.04/py/BUILD'
      dest: '{{ TENSORFLOW_BUILD_DIR }}/third_party/py/BUILD'

  when: TF_MAIN_VERSION.stdout|int == 2 and TF_RELEASE.stdout|int > 0

# For RHEL 8 only (and thus ubi8), as well as TensorFlow version > 2.0.0, we have to create symbolic links for python3.6
- block:

  - name: Edit the BUILD file to change the interpreter path from /usr/bin/python2 to /usr/bin/python3
    replace:
      path: '{{ TENSORFLOW_BUILD_DIR }}/third_party/py/BUILD'
      regexp: '    interpreter_path = "/usr/bin/python2",'
      replace: '    interpreter_path = "/usr/bin/python3",'

  - name: Edit the BUILD file to change all 'python2.7' strings to 'python3.6m' strings
    replace:
      path: '{{ TENSORFLOW_BUILD_DIR }}/third_party/py/BUILD'
      regexp: 'python2.7'
      replace: 'python3.6m'

  - name: Create symbolic link for /usr/local/include/python3.6m by setting it to point to /usr/include/python3.6m
    file:
      src: '/usr/include/python3.6m'
      dest: '/usr/local/include/python3.6m'
      state: link

  - name: Replace 'dist-packages' with 'site-packages' in the BUILD file, because 'dist-packages' is for Ubuntu and 'site-packages' is for RHEL
    replace:
      path: '{{ TENSORFLOW_BUILD_DIR }}/third_party/py/BUILD'
      regexp: 'dist-packages'
      replace: 'site-packages'

  - name: Create directory which we will use for a symbolic link w/ NumPy
    file:
      state: directory
      path: '/usr/local/lib/python3.6m/site-packages'

  - name: Create symbolic link for /usr/local/lib/python3.6/site-packages by setting it to point to '{{ NUMPY_INSTALL_DIR }}'
    file:
      src: '{{ NUMPY_INSTALL_DIR }}/lib64/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy'
      dest: '/usr/local/lib/python3.6m/site-packages/numpy'
      state: link

  - name: Create symbolic link that causes /usr/bin/python to point to /usr/bin/python3
    file:
      state: link
      src: '/usr/bin/python3'
      dest: '/usr/bin/python'

  when: TF_MAIN_VERSION.stdout|int == 2 and TF_RELEASE.stdout|int > 0 and RHEL_VERSION|int == 8

# Update 'WORKSPACE' for TensorFlow 1.x
- name: TensorFlow 1.x workaround --> update {{ TENSORFLOW_BUILD_DIR }}/WORKSPACE to add the 'io_bazel_rules_docker' http archive so that bazel rules can be cloned
  blockinfile:
    path: '{{ TENSORFLOW_BUILD_DIR }}/WORKSPACE'
    insertafter: 'load\(\"\@bazel\_tools\/\/tools\/build\_defs\/repo:http.bzl\",\ \"http_archive\",\ \"http_file"\)'
    block: |
      http_archive(
          name = "io_bazel_rules_docker",
          sha256 = "aed1c249d4ec8f703edddf35cbe9dfaca0b5f5ea6e4cd9e83e99f3b0d1136c3d",
          strip_prefix = "rules_docker-0.7.0",
          urls = ["https://github.com/bazelbuild/rules_docker/archive/v0.7.0.tar.gz"],
      )
  when: TF_MAIN_VERSION.stdout|int < 2

# The WORKSPACE file is missing info, so we need to add the missing info to it
- name: Edit WORKSPACE file to include 'local_python_config' so that the build doesn't fail (as per the TensorFlow maintainers' suggestion)
  blockinfile:
    path: '{{ TENSORFLOW_BUILD_DIR }}/WORKSPACE'
    insertafter: '^tf_repositories()'
    block: |
      load("//third_party/py:python_configure.bzl", "python_configure")
      python_configure(name = "local_config_python")
  when: TF_MAIN_VERSION.stdout|int == 2 and TF_RELEASE.stdout|int > 0

# ./tensorflow/workspace.bzl needs fixing, too, if we're using TF 2.1.0 because the 'pybind11' module pulls a URL that doesn't exist
- block:

  - name: For TensorFlow 2.1.0 ONLY --> Edit {{ TENSORFLOW_BUILD_DIR }}/tensorflow/workspace.bzl to update the 'pybind11' module Bazel download URL no. 1
    replace:
      path: '{{ TENSORFLOW_BUILD_DIR }}/tensorflow/workspace.bzl'
      regexp: 'https://mirror.bazel.build/github.com/pybind/pybind11/archive/v2.3.0.tar.gz'
      replace: 'https://storage.googleapis.com/mirror.tensorflow.org/github.com/pybind/pybind11/archive/v2.4.3.tar.gz'

  - name: For TensorFlow 2.1.0 ONLY --> Edit {{ TENSORFLOW_BUILD_DIR }}/tensorflow/workspace.bzl to update the 'pybind11' module Bazel download URL no. 2
    replace:
      path: '{{ TENSORFLOW_BUILD_DIR }}/tensorflow/workspace.bzl'
      regexp: 'https://github.com/pybind/pybind11/archive/v2.3.0.tar.gz'
      replace: 'https://github.com/pybind/pybind11/archive/v2.4.3.tar.gz'

  - name: For TensorFlow 2.1.0 ONLY --> Edit {{ TENSORFLOW_BUILD_DIR }}/tensorflow/workspace.bzl to update the 'pybind11' module's SHA256 value
    replace:
      path: '{{ TENSORFLOW_BUILD_DIR }}/tensorflow/workspace.bzl'
      regexp: '0f34838f2c8024a6765168227ba587b3687729ebf03dc912f88ff75c7aa9cfe8'
      replace: '1eed57bc6863190e35637290f97a20c81cfe4d9090ac0a24f3bbf08f265eb71d'

  - name: For TensoRFlow 2.1.0 ONLY --> Edit {{ TENSORFLOW_BUILD_DIR }}/tensorflow/workspace.bzl to update the 'pybind11' module's 'strip_prefix' value
    replace:
      path: '{{ TENSORFLOW_BUILD_DIR }}/tensorflow/workspace.bzl'
      regexp: 'pybind11-2.3.0'
      replace: 'pybind11-2.4.3'

  when: TF_MAIN_VERSION.stdout|int == 2 and TF_RELEASE.stdout|int == 1

# Now configure TensorFlow for the CPU
- name: RHEL 7 and ubi7 ONLY --> Configure TensorFlow for the CPU
  shell: |
    cd {{ TENSORFLOW_BUILD_DIR }} 
    ./configure
  environment:
    GCC_HOST_COMPILER_PATH: '{{ CC }}'
    CC_OPT_FLAGS: '-march=native'
    TF_DOWNLOAD_CLANG: '0'
    TF_ENABLE_XLA: '1'
    TF_NEED_COMPUTECPP: '0'
    TF_NEED_CUDA: '0'
    TF_NEED_MPI: '0'
    TF_NEED_OPENCL: '0'
    TF_NEED_OPENCL_SYCL: '0'
    TF_NEED_ROCM: '0'
    TF_NEED_TENSORRT: '0'
    TF_PYTHON_CONFIG_REPO: '@org_tensorflow//third_party/toolchains/cpus/py3'
    TF_SET_ANDROID_WORKSPACE: '0'
    PYTHON_BIN_PATH: '{{ PYTHON_BIN_PATH }}'
    PYTHON_LIB_PATH: '{{ PYTHONPATH }}'
    NUMPY_INCLUDE_DIR: '{{ NUMPY_INSTALL_DIR }}/lib/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core/include/numpy'
    LD_LIBRARY_PATH: '{{ NUMPY_INSTALL_DIR }}/lib/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core:{{ GCC_LIBS }}'
  when: DEVICE == 'cpu' and RHEL_VERSION|int == 7

- name: RHEL 8 and ubi8 ONLY --> Configure TensorFlow for the CPU
  shell: |
    cd {{ TENSORFLOW_BUILD_DIR }} 
    ./configure
  environment:
    GCC_HOST_COMPILER_PATH: '{{ CC }}'
    CC_OPT_FLAGS: '-march=native'
    TF_DOWNLOAD_CLANG: '0'
    TF_ENABLE_XLA: '1'
    TF_NEED_COMPUTECPP: '0'
    TF_NEED_CUDA: '0'
    TF_NEED_MPI: '0'
    TF_NEED_OPENCL: '0'
    TF_NEED_OPENCL_SYCL: '0'
    TF_NEED_ROCM: '0'
    TF_NEED_TENSORRT: '0'
    TF_PYTHON_CONFIG_REPO: '@org_tensorflow//third_party/toolchains/cpus/py3'
    TF_SET_ANDROID_WORKSPACE: '0'
    PYTHON_BIN_PATH: '{{ PYTHON_BIN_PATH }}'
    PYTHON_LIB_PATH: '{{ PYTHONPATH }}'
    NUMPY_INCLUDE_DIR: '{{ NUMPY_INSTALL_DIR }}/lib64/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core/include/numpy'
    LD_LIBRARY_PATH: '{{ NUMPY_INSTALL_DIR }}/lib64/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core:{{ GCC_LIBS }}'
  when: DEVICE == 'cpu' and RHEL_VERSION|int == 8

- block:
  # Command taken from: https://georgesterpu.github.io/compile_tensorflow.html
  - name: If using the GPU, find the exact CUDA version
    shell: /usr/local/cuda/bin/nvcc --version | sed -n 's/^.*release \(.*\),.*/\1/p'
    register: cuda_version

  # Command taken from: https://georgesterpu.github.io/compile_tensorflow.html
  - name: If using the GPU, find cuDNN version
    shell: sed -n 's/^#define CUDNN_MAJOR\s*\(.*\).*/\1/p' /usr/local/cuda/include/cudnn.h
    register: cudnn_version

  # Grab the NCCL major version
  - name: If using the GPU, find NCCL major version
    shell: sed -n 's/^#define NCCL_MAJOR\s*\(.*\).*/\1/p' '{{ NCCL_INSTALL_PATH }}/include/nccl.h'
    register: nccl_major_version

  # Grab NCCL minor version
  - name: If using the GPU, find NCCL minor version
    shell: sed -n 's/^#define NCCL_MINOR\s*\(.*\).*/\1/p' '{{ NCCL_INSTALL_PATH }}/include/nccl.h'
    register: nccl_minor_version

  # Grab NCCL patch
  - name: If using the GPU, find NCCL patch
    shell: sed -n 's/^#define NCCL_PATCH\s*\(.*\).*/\1/p' '{{ NCCL_INSTALL_PATH }}/include/nccl.h'
    register: nccl_patch

  # Print out versions
  - debug:
      msg: 'CUDA version: {{ cuda_version.stdout }}'
  - debug:
      msg: 'cuDNN version: {{ cudnn_version.stdout }}'
  - debug:
      msg: 'NCCL version: {{ nccl_major_version.stdout }}.{{ nccl_minor_version.stdout }}.{{ nccl_patch.stdout }}'

  when: DEVICE == 'gpu'

# Get TensorRT version
- block:

  - name: If using the GPU and using TensorRT, find the TensorRT major version
    shell: sed -n 's/^#define NV_TENSORRT_MAJOR\s*\(.*\).*/\1/p' '{{ TENSORRT_INSTALL_PATH }}/include/NvInferVersion.h' | cut -d ' ' -f 1
    register: tensorrt_version

  - debug:
      msg: 'TensorRT version: {{ tensorrt_version.stdout }}'

  when: DEVICE == 'gpu' and USE_TENSORRT == 'yes'

# Now configure TensorFlow for the GPU
- name: Configure TensorFlow for the GPU w/o TensorRT
  shell: |
    cd {{ TENSORFLOW_BUILD_DIR }} 
    ./configure
  environment:
    GCC_HOST_COMPILER_PATH: '{{ CC }}'
    CC_OPT_FLAGS: '-march=native'
    TF_CUDA_PATHS: '/usr/local/cuda,/usr/include,{{ NCCL_INSTALL_PATH }}'
    TF_DOWNLOAD_CLANG: '0'
    TF_ENABLE_XLA: '0'
    TF_NEED_COMPUTECPP: '0'
    TF_NEED_CUDA: '1'
    TF_NEED_MPI: '0'
    TF_NEED_OPENCL: '0'
    TF_NEED_OPENCL_SYCL: '0'
    TF_NEED_ROCM: '0'
    TF_NEED_TENSORRT: '0'
    TF_SET_ANDROID_WORKSPACE: '0'
    PYTHON_BIN_PATH: '{{ PYTHON_BIN_PATH }}'
    PYTHON_LIB_PATH: '{{ PYTHONPATH }}'
    NUMPY_INCLUDE_DIR: '{{ NUMPY_INSTALL_DIR }}/lib/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core/include/numpy'
    LD_LIBRARY_PATH: '{{ NUMPY_INSTALL_DIR }}/lib/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core:{{ GCC_LIBS }}'
  when: DEVICE == 'gpu' and USE_TENSORRT == 'no'

# Now configure TensorFlow for the GPU
- name: Configure TensorFlow for the GPU w/ TensorRT
  shell: |
    cd {{ TENSORFLOW_BUILD_DIR }} 
    ./configure
  environment:
    GCC_HOST_COMPILER_PATH: '{{ CC }}'
    CC_OPT_FLAGS: '-march=native'
    TF_CUDA_PATHS: '/usr/local/cuda,/usr/include,{{ NCCL_INSTALL_PATH }},{{ TENSORRT_INSTALL_PATH }}'
    TF_CUDA_VERSION: '{{ cuda_version.stdout }}'
    TF_CUDNN_VERSION: '{{ cudnn_version.stdout }}'
    TF_DOWNLOAD_CLANG: '0'
    TF_ENABLE_XLA: '0'
    TF_NCCL_VERSION: '{{ nccl_major_version.stdout }}'
    TF_NEED_COMPUTECPP: '0'
    TF_NEED_CUDA: '1'
    TF_NEED_MPI: '0'
    TF_NEED_OPENCL: '0'
    TF_NEED_OPENCL_SYCL: '0'
    TF_NEED_ROCM: '0'
    TF_NEED_TENSORRT: '1'
    TF_SET_ANDROID_WORKSPACE: '0'
    TF_TENSORRT_VERSION: '{{ tensorrt_version.stdout }}'
    PYTHON_BIN_PATH: '{{ PYTHON_BIN_PATH }}'
    PYTHON_LIB_PATH: '{{ PYTHONPATH }}'
    NUMPY_INCLUDE_DIR: '{{ NUMPY_INSTALL_DIR }}/lib/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core/include/numpy'
    LD_LIBRARY_PATH: '{{ NUMPY_INSTALL_DIR }}/lib/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core:{{ GCC_LIBS }}'
  when: DEVICE == 'gpu' and USE_TENSORRT == 'yes'

# Print out where the configure logs have been saved to
- debug:
    msg: "TensorFlow config logs saved to {{ TENSORFLOW_BUILD_DIR }}/configure.log"

# TensorFlow 2.1.0 requires a '/root/.bazelrc' file, so let's just copy it from `pwd`/.tf_config_bazelrc
- name: Move {{ TENSORFLOW_BUILD_DIR }}/.bazelrc to /root/.bazelrc
  shell: 'mv {{ TENSORFLOW_BUILD_DIR }}/.bazelrc /root/.bazelrc'
  when: TF_MAIN_VERSION.stdout|int == 2 and TF_RELEASE.stdout|int > 0

# Now it's time to build TensorFlow for the CPU. We want to use the optimization flags that we
# found earlier, if applicable. However, we must build TensorFlow differently on RHEL 7 (and thus
# ubi7) than on RHEL 8 (and thus ubi8). The following block is for *RHEL 7*
- block:
  - name: Build TensorFlow for the CPU using user defined AVX* flags and user defined SSE* flags
    shell: |
      cd {{ TENSORFLOW_BUILD_DIR }}
      bazel build --copt=-mfpmath=both {{ ENABLE_AVX.stdout }} {{ ENABLE_AVX2.stdout }} {{ ENABLE_AVX512.stdout }} {{ ENABLE_FMA.stdout }} {{ ENABLE_SSE2.stdout }} {{ ENABLE_SSE3.stdout }} {{ ENABLE_SSE4_1.stdout }} {{ ENABLE_SSE4_2.stdout }} --config=opt //tensorflow/tools/pip_package:build_pip_package
    when: AVX_SETTINGS.stdout == 'user_defined' and SSE_SETTINGS.stdout == 'user_defined'
    environment:
      LD_LIBRARY_PATH: '{{ NUMPY_INSTALL_DIR }}/lib/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core:{{ GCC_LIBS }}'

  - name: Build TensorFlow for the CPU using default (optimized) AVX* flags, but user defined SSE* flags
    shell: |
      cd {{ TENSORFLOW_BUILD_DIR }}
      bazel build --copt=-mfpmath=both {{ DEFAULT_ENABLE_AVX.stdout }} {{ DEFAULT_ENABLE_AVX2.stdout }} {{ DEFAULT_ENABLE_AVX512.stdout }} {{ DEFAULT_ENABLE_FMA.stdout }} {{ ENABLE_SSE2.stdout }} {{ ENABLE_SSE3.stdout }} {{ ENABLE_SSE4_1.stdout }} {{ ENABLE_SSE4_2.stdout }} --config=opt //tensorflow/tools/pip_package:build_pip_package
    when: AVX_SETTINGS.stdout == 'default' and SSE_SETTINGS.stdout == 'user_defined'
    environment:
      LD_LIBRARY_PATH: '{{ NUMPY_INSTALL_DIR }}/lib/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core:{{ GCC_LIBS }}'

  - name: Build TensorFlow for the CPU using user defined AVX* flags, but default SSE* flags
    shell: |
      cd {{ TENSORFLOW_BUILD_DIR }}
      bazel build --copt=-mfpmath=both {{ ENABLE_AVX.stdout }} {{ ENABLE_AVX2.stdout }} {{ ENABLE_AVX512.stdout }} {{ ENABLE_FMA.stdout }} {{ DEFAULT_ENABLE_SSE2.stdout }} {{ DEFAULT_ENABLE_SSE3.stdout }} {{ DEFAULT_ENABLE_SSE4_1.stdout }} {{ DEFAULT_ENABLE_SSE4_2.stdout }} --config=opt //tensorflow/tools/pip_package:build_pip_package
    when: AVX_SETTINGS.stdout == 'user_defined' and SSE_SETTINGS.stdout == 'default'
    environment:
      LD_LIBRARY_PATH: '{{ NUMPY_INSTALL_DIR }}/lib/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core:{{ GCC_LIBS }}'

  - name: Build TensorFlow for the CPU using default (optimized) AVX* flags and default (optimized) SSE* flags
    shell: |
      cd {{ TENSORFLOW_BUILD_DIR }}
      bazel build --copt=-mfpmath=both {{ DEFAULT_ENABLE_AVX.stdout }} {{ DEFAULT_ENABLE_AVX2.stdout }} {{ DEFAULT_ENABLE_AVX512.stdout }} {{ DEFAULT_ENABLE_FMA.stdout }} {{ DEFAULT_ENABLE_SSE2.stdout }} {{ DEFAULT_ENABLE_SSE3.stdout }} {{ DEFAULT_ENABLE_SSE4_1.stdout }} {{ DEFAULT_ENABLE_SSE4_2.stdout }} --config=opt //tensorflow/tools/pip_package:build_pip_package
    when: AVX_SETTINGS.stdout == 'default' and SSE_SETTINGS.stdout == 'default'
    environment:
      LD_LIBRARY_PATH: '{{ NUMPY_INSTALL_DIR }}/lib/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core:{{ GCC_LIBS }}'

  when: DEVICE == 'cpu' and RHEL_VERSION|int == 7

# For RHEL 8, NumPy is installed in {{ NUMPY_INSTALL_DIR }}/lib64. We also don't
# have 'ares.h' installed, so we must tell bazel to *NOT* use ares when building
# the required 'grpc' module.
- block:
  - name: Build TensorFlow for the CPU using user defined AVX* flags and user defined SSE* flags
    shell: |
      cd {{ TENSORFLOW_BUILD_DIR }}
      bazel build --define=grpc_no_ares=true --copt=-mfpmath=both {{ ENABLE_AVX.stdout }} {{ ENABLE_AVX2.stdout }} {{ ENABLE_AVX512.stdout }} {{ ENABLE_FMA.stdout }} {{ ENABLE_SSE2.stdout }} {{ ENABLE_SSE3.stdout }} {{ ENABLE_SSE4_1.stdout }} {{ ENABLE_SSE4_2.stdout }} --config=opt //tensorflow/tools/pip_package:build_pip_package
    when: AVX_SETTINGS.stdout == 'user_defined' and SSE_SETTINGS.stdout == 'user_defined'
    environment:
      LD_LIBRARY_PATH: '{{ NUMPY_INSTALL_DIR }}/lib64/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core:{{ GCC_LIBS }}'

  - name: Build TensorFlow for the CPU using default (optimized) AVX* flags, but user defined SSE* flags
    shell: |
      cd {{ TENSORFLOW_BUILD_DIR }}
      bazel build --define=grpc_no_ares=true --copt=-mfpmath=both {{ DEFAULT_ENABLE_AVX.stdout }} {{ DEFAULT_ENABLE_AVX2.stdout }} {{ DEFAULT_ENABLE_AVX512.stdout }} {{ DEFAULT_ENABLE_FMA.stdout }} {{ ENABLE_SSE2.stdout }} {{ ENABLE_SSE3.stdout }} {{ ENABLE_SSE4_1.stdout }} {{ ENABLE_SSE4_2.stdout }} --config=opt //tensorflow/tools/pip_package:build_pip_package
    when: AVX_SETTINGS.stdout == 'default' and SSE_SETTINGS.stdout == 'user_defined'
    environment:
      LD_LIBRARY_PATH: '{{ NUMPY_INSTALL_DIR }}/lib64/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core:{{ GCC_LIBS }}'

  - name: Build TensorFlow for the CPU using user defined AVX* flags, but default SSE* flags
    shell: |
      cd {{ TENSORFLOW_BUILD_DIR }}
      bazel build --define=grpc_no_ares=true --copt=-mfpmath=both {{ ENABLE_AVX.stdout }} {{ ENABLE_AVX2.stdout }} {{ ENABLE_AVX512.stdout }} {{ ENABLE_FMA.stdout }} {{ DEFAULT_ENABLE_SSE2.stdout }} {{ DEFAULT_ENABLE_SSE3.stdout }} {{ DEFAULT_ENABLE_SSE4_1.stdout }} {{ DEFAULT_ENABLE_SSE4_2.stdout }} --config=opt //tensorflow/tools/pip_package:build_pip_package
    when: AVX_SETTINGS.stdout == 'user_defined' and SSE_SETTINGS.stdout == 'default'
    environment:
      LD_LIBRARY_PATH: '{{ NUMPY_INSTALL_DIR }}/lib64/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core:{{ GCC_LIBS }}'

  - name: Build TensorFlow for the CPU using default (optimized) AVX* flags and default (optimized) SSE* flags
    shell: |
      cd {{ TENSORFLOW_BUILD_DIR }}
      bazel build --define=grpc_no_ares=true --copt=-mfpmath=both {{ DEFAULT_ENABLE_AVX.stdout }} {{ DEFAULT_ENABLE_AVX2.stdout }} {{ DEFAULT_ENABLE_AVX512.stdout }} {{ DEFAULT_ENABLE_FMA.stdout }} {{ DEFAULT_ENABLE_SSE2.stdout }} {{ DEFAULT_ENABLE_SSE3.stdout }} {{ DEFAULT_ENABLE_SSE4_1.stdout }} {{ DEFAULT_ENABLE_SSE4_2.stdout }} --config=opt //tensorflow/tools/pip_package:build_pip_package
    when: AVX_SETTINGS.stdout == 'default' and SSE_SETTINGS.stdout == 'default'
    environment:
      LD_LIBRARY_PATH: '{{ NUMPY_INSTALL_DIR }}/lib64/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core:{{ GCC_LIBS }}'

  when: DEVICE == 'cpu' and RHEL_VERSION|int == 8

# Same as above, except for the GPU
- block:
  - name: Build TensorFlow for the GPU using user defined AVX* flags and user defined SSE* flags
    shell: |
      cd {{ TENSORFLOW_BUILD_DIR }}
      bazel build --copt="-I/usr/include" --copt=-mfpmath=both {{ ENABLE_AVX.stdout }} {{ ENABLE_AVX2.stdout }} {{ ENABLE_AVX512.stdout }} {{ ENABLE_FMA.stdout }} {{ ENABLE_SSE2.stdout }} {{ ENABLE_SSE3.stdout }} {{ ENABLE_SSE4_1.stdout }} {{ ENABLE_SSE4_2.stdout }} --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
    when: AVX_SETTINGS.stdout == 'user_defined' and SSE_SETTINGS.stdout == 'user_defined'
    environment:
      LD_LIBRARY_PATH: '{{ NUMPY_INSTALL_DIR }}/lib/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core:{{ GCC_LIBS }}'

  - name: Build TensorFlow for the GPU using default (optimized) AVX* flags, but user defined SSE* flags
    shell: |
      cd {{ TENSORFLOW_BUILD_DIR }}
      bazel build --copt="-I/usr/include" --copt=-mfpmath=both {{ DEFAULT_ENABLE_AVX.stdout }} {{ DEFAULT_ENABLE_AVX2.stdout }} {{ DEFAULT_ENABLE_AVX512.stdout }} {{ DEFAULT_ENABLE_FMA.stdout }} {{ ENABLE_SSE2.stdout }} {{ ENABLE_SSE3.stdout }} {{ ENABLE_SSE4_1.stdout }} {{ ENABLE_SSE4_2.stdout }} --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
    when: AVX_SETTINGS.stdout == 'default' and SSE_SETTINGS.stdout == 'user_defined'
    environment:
      LD_LIBRARY_PATH: '{{ NUMPY_INSTALL_DIR }}/lib/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core:{{ GCC_LIBS }}'

  - name: Build TensorFlow for the GPU using user defined AVX* flags, but default SSE* flags
    shell: |
      cd {{ TENSORFLOW_BUILD_DIR }}
      bazel build --copt="-I/usr/include" --copt=-mfpmath=both {{ ENABLE_AVX.stdout }} {{ ENABLE_AVX2.stdout }} {{ ENABLE_AVX512.stdout }} {{ ENABLE_FMA.stdout }} {{ DEFAULT_ENABLE_SSE2.stdout }} {{ DEFAULT_ENABLE_SSE3.stdout }} {{ DEFAULT_ENABLE_SSE4_1.stdout }} {{ DEFAULT_ENABLE_SSE4_2.stdout }} --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
    when: AVX_SETTINGS.stdout == 'user_defined' and SSE_SETTINGS.stdout == 'default'
    environment:
      LD_LIBRARY_PATH: '{{ NUMPY_INSTALL_DIR }}/lib/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core:{{ GCC_LIBS }}'

  - name: Build TensorFlow for the GPU using default (optimized) AVX* flags and default (optimized) SSE* flags
    shell: |
      cd {{ TENSORFLOW_BUILD_DIR }}
      bazel build --copt="-I/usr/include" --copt=-mfpmath=both {{ DEFAULT_ENABLE_AVX.stdout }} {{ DEFAULT_ENABLE_AVX2.stdout }} {{ DEFAULT_ENABLE_AVX512.stdout }} {{ DEFAULT_ENABLE_FMA.stdout }} {{ DEFAULT_ENABLE_SSE2.stdout }} {{ DEFAULT_ENABLE_SSE3.stdout }} {{ DEFAULT_ENABLE_SSE4_1.stdout }} {{ DEFAULT_ENABLE_SSE4_2.stdout }} --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
    when: AVX_SETTINGS.stdout == 'default' and SSE_SETTINGS.stdout == 'default'
    environment:
      LD_LIBRARY_PATH: '{{ NUMPY_INSTALL_DIR }}/lib/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core:{{ GCC_LIBS }}'

  when: DEVICE == 'gpu' and RHEL_VERSION|int == 7

- block:
  - name: Build TensorFlow for the GPU using user defined AVX* flags and user defined SSE* flags
    shell: |
      cd {{ TENSORFLOW_BUILD_DIR }}
      bazel build --define=grpc_no_ares=true --copt="-I/usr/include" --copt=-mfpmath=both {{ ENABLE_AVX.stdout }} {{ ENABLE_AVX2.stdout }} {{ ENABLE_AVX512.stdout }} {{ ENABLE_FMA.stdout }} {{ ENABLE_SSE2.stdout }} {{ ENABLE_SSE3.stdout }} {{ ENABLE_SSE4_1.stdout }} {{ ENABLE_SSE4_2.stdout }} --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
    when: AVX_SETTINGS.stdout == 'user_defined' and SSE_SETTINGS.stdout == 'user_defined'
    environment:
      LD_LIBRARY_PATH: '{{ NUMPY_INSTALL_DIR }}/lib64/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core:{{ GCC_LIBS }}'

  - name: Build TensorFlow for the GPU using default (optimized) AVX* flags, but user defined SSE* flags
    shell: |
      cd {{ TENSORFLOW_BUILD_DIR }}
      bazel build --define=grpc_no_ares=true --copt="-I/usr/include" --copt=-mfpmath=both {{ DEFAULT_ENABLE_AVX.stdout }} {{ DEFAULT_ENABLE_AVX2.stdout }} {{ DEFAULT_ENABLE_AVX512.stdout }} {{ DEFAULT_ENABLE_FMA.stdout }} {{ ENABLE_SSE2.stdout }} {{ ENABLE_SSE3.stdout }} {{ ENABLE_SSE4_1.stdout }} {{ ENABLE_SSE4_2.stdout }} --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
    when: AVX_SETTINGS.stdout == 'default' and SSE_SETTINGS.stdout == 'user_defined'
    environment:
      LD_LIBRARY_PATH: '{{ NUMPY_INSTALL_DIR }}/lib64/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core:{{ GCC_LIBS }}'

  - name: Build TensorFlow for the GPU using user defined AVX* flags, but default SSE* flags
    shell: |
      cd {{ TENSORFLOW_BUILD_DIR }}
      bazel build --define=grpc_no_ares=true --copt="-I/usr/include" --copt=-mfpmath=both {{ ENABLE_AVX.stdout }} {{ ENABLE_AVX2.stdout }} {{ ENABLE_AVX512.stdout }} {{ ENABLE_FMA.stdout }} {{ DEFAULT_ENABLE_SSE2.stdout }} {{ DEFAULT_ENABLE_SSE3.stdout }} {{ DEFAULT_ENABLE_SSE4_1.stdout }} {{ DEFAULT_ENABLE_SSE4_2.stdout }} --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
    when: AVX_SETTINGS.stdout == 'user_defined' and SSE_SETTINGS.stdout == 'default'
    environment:
      LD_LIBRARY_PATH: '{{ NUMPY_INSTALL_DIR }}/lib64/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core:{{ GCC_LIBS }}'

  - name: Build TensorFlow for the GPU using default (optimized) AVX* flags and default (optimized) SSE* flags
    shell: |
      cd {{ TENSORFLOW_BUILD_DIR }}
      bazel build --define=grpc_no_ares=true --copt="-I/usr/include" --copt=-mfpmath=both {{ DEFAULT_ENABLE_AVX.stdout }} {{ DEFAULT_ENABLE_AVX2.stdout }} {{ DEFAULT_ENABLE_AVX512.stdout }} {{ DEFAULT_ENABLE_FMA.stdout }} {{ DEFAULT_ENABLE_SSE2.stdout }} {{ DEFAULT_ENABLE_SSE3.stdout }} {{ DEFAULT_ENABLE_SSE4_1.stdout }} {{ DEFAULT_ENABLE_SSE4_2.stdout }} --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
    when: AVX_SETTINGS.stdout == 'default' and SSE_SETTINGS.stdout == 'default'
    environment:
      LD_LIBRARY_PATH: '{{ NUMPY_INSTALL_DIR }}/lib64/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core:{{ GCC_LIBS }}'

  when: DEVICE == 'gpu' and RHEL_VERSION|int == 8

- debug:
    msg: "TensorFlow build logs saved to {{ TENSORFLOW_BUILD_DIR }}/build.log"

- name: Build pip package with Bazel
  shell: |
    cd {{ TENSORFLOW_BUILD_DIR }}
    ./bazel-bin/tensorflow/tools/pip_package/build_pip_package {{ TF_PIP_PACKAGE_LOCATION }}

- name: Shutdown bazel
  shell: bazel shutdown

- name: Remove bazel cache because it is very large and we don't need it anymore
  shell: rm -rf /root/.cache/bazel
