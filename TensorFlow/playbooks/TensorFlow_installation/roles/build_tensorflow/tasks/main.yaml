---

# First step is to determine if we have any AVX* instructions that we can take advantage of
- name: Determine if we have AVX instructions
  shell: |
    avx=$(lscpu | grep 'Flags' | grep avx)
    echo $avx
  register: HAVE_AVX

- name: Determine if we have AVX2 instructions
  shell: |
    avx2=$(lscpu | grep 'Flags' | grep avx2)
    echo $avx2
  register: HAVE_AVX2

# XXX:TODO --> Make check to see which version of gcc is being used. TensorFlow requires
# gcc version 4.9 or greater if using -mavx512f, -mavx512dq, etc.
#- name: Determine if we have AVX512F instructions
#  shell: |
#    avx512f=$(lscpu | grep 'Flags' | grep avx512f)
#    echo $avx512f
#  register: HAVE_AVX512F
#
#- name: Determine if we have AVX512DQ instructions
#  shell: |
#    avx512dq=$(lscpu | grep 'Flags' | grep avx512dq)
#    echo $avx512dq
#  register: HAVE_AVX512DQ
#
#- name: Determine if we have AVX512CD instructions
#  shell: |
#    avx512cd=$(lscpu | grep 'Flags' | grep avx512cd)
#    echo $avx512cd
#  register: HAVE_AVX512CD

# Next step is to determine if we have FMA instructions that we can take advantage of
- name: Determine if we have FMA instructions
  shell: |
    fma=$(lscpu | grep 'Flags' | grep fma)
    echo $fma
  register: HAVE_FMA

# Now determine SSE* instructions
- name: Determine if we have SSE2 instructions
  shell: |
    sse2=$(lscpu | grep 'Flags' | grep sse2)
    echo $sse2
  register: HAVE_SSE2

- name: Determine if we have SSE3 instructions
  shell: |
    sse3=$(lscpu | grep 'Flags' | grep sse3)
    echo $sse3
  register: HAVE_SSE3

- name: Determine if we have SSE4.1 instructions
  shell: |
    sse4_1=$(lscpu | grep 'Flags' | grep sse4_1)
    echo $sse4_1
  register: HAVE_SSE4_1

- name: Determine if we have SSE4.2 instructions
  shell: |
    sse4_2=$(lscpu | grep 'Flags' | grep sse4_2)
    echo $sse4_2
  register: HAVE_SSE4_2

# Now that we've gathered information on optimization flags, let's set them appropriately
- name: Set AVX copt flag
  shell: if [[ ! -z '{{ HAVE_AVX.stdout }}' ]]; then echo "--copt=-mavx"; else echo ""; fi
  register: ENABLE_AVX

- name: Set AVX2 copt flag
  shell: if [[ ! -z '{{ HAVE_AVX2.stdout }}' ]]; then echo "--copt=-mavx2"; else echo ""; fi
  register: ENABLE_AVX2

#- name: Set AVX512 copt flag
#  shell: if [[ ! -z '{{ HAVE_AVX512F.stdout }}' ]]; then echo "--copt=-mavx512f"; elif [[ ! -z '{{ HAVE_AVX512DQ.stdout }}' ]]; then echo "--copt=-mavx512dq"; elif [[ ! -z '{{ HAVE_AVX512CD.stdout }}' ]]; then echo "--copt=-mavx512cd"; else echo ""; fi
#  register: ENABLE_AVX512

- name: Set FMA copt flag
  shell: if [[ ! -z '{{ HAVE_FMA.stdout }}' ]]; then echo "--copt=-mfma"; else echo ""; fi
  register: ENABLE_FMA

- name: Set SSE2 copt flag
  shell: if [[ ! -z '{{ HAVE_SSE2.stdout }}' ]]; then echo "--copt=-msse2"; else echo ""; fi
  register: ENABLE_SSE2

- name: Set SSE3 copt flag
  shell: if [[ ! -z '{{ HAVE_SSE3.stdout }}' ]]; then echo "--copt=-msse3"; else echo ""; fi
  register: ENABLE_SSE3

- name: Set SSE4.1 copt flag
  shell: if [[ ! -z '{{ HAVE_SSE4_1.stdout }}' ]]; then echo "--copt=-msse4.1"; else echo ""; fi
  register: ENABLE_SSE4_1

- name: Set SSE4.2 copt flag
  shell: if [[ ! -z '{{ HAVE_SSE4_2.stdout }}' ]]; then echo "--copt=-msse4.2"; else echo ""; fi
  register: ENABLE_SSE4_2

# Now let's print out our final compilation flags
- debug:
    msg: "Build flags: {{ ENABLE_AVX.stdout }} {{ ENABLE_AVX2.stdout }} {{ ENABLE_FMA.stdout }} {{ ENABLE_SSE2.stdout }} {{ ENABLE_SSE3.stdout }} {{ ENABLE_SSE4_1.stdout }} {{ ENABLE_SSE4_2.stdout }}"

# Now configure TensorFlow for the CPU
- name: Configure TensorFlow for the CPU
  shell: |
    cd {{ TENSORFLOW_BUILD_DIR }} 
    ./configure
  environment:
    GCC_HOST_COMPILER_PATH: '/usr/bin/gcc'
    CC_OPT_FLAGS: '-march=native'
    TF_DOWNLOAD_CLANG: '0'
    TF_ENABLE_XLA: '0'
    TF_NEED_COMPUTECPP: '0'
    TF_NEED_CUDA: '0'
    TF_NEED_MPI: '0'
    TF_NEED_OPENCL: '0'
    TF_NEED_OPENCL_SYCL: '0'
    TF_NEED_ROCM: '0'
    TF_NEED_TENSORRT: '0'
    TF_PYTHON_CONFIG_REPO: '@org_tensorflow//third_party/toolchains/cpus/py'
    TF_SET_ANDROID_WORKSPACE: '0'
    PYTHON_BIN_PATH: '{{ PYTHON_BIN_PATH }}'
    PYTHON_LIB_PATH: '{{ PYTHON_LIB_PATH }}'
    NUMPY_INCLUDE_DIR: '{{ NUMPY_INSTALL_DIR }}/lib64/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core/include/numpy'
    LD_LIBRARY_PATH: '{{ NUMPY_INSTALL_DIR }}/lib64/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core'
  register: tensorflow_configure_log_cpu
  when: USE_CPU == 'yes' and USE_GPU == 'no'

# Command taken from: https://georgesterpu.github.io/compile_tensorflow.html
- name: If using the GPU, find CUDA version
  shell: /usr/local/cuda/bin/nvcc --version | sed -n 's/^.*release \(.*\),.*/\1/p'
  register: cuda_version
  when: USE_CPU == 'no' and USE_GPU == 'yes'

# Command taken from: https://georgesterpu.github.io/compile_tensorflow.html
- name: If using the GPU, find cuDNN version
  shell: sed -n 's/^#define CUDNN_MAJOR\s*\(.*\).*/\1/p' /usr/local/cuda/include/cudnn.h
  register: cudnn_version
  when: USE_CPU == 'no' and USE_GPU == 'yes'

# Now configure TensorFlow for the GPU
- name: Configure TensorFlow for the GPU
  shell: |
    cd {{ TENSORFLOW_BUILD_DIR }} 
    ./configure
  environment:
    GCC_HOST_COMPILER_PATH: '/usr/bin/gcc'
    CC_OPT_FLAGS: '-march=native'
    CUDA_TOOLKIT_PATH: '/usr/local/cuda'
    CUDNN_INSTALL_PATH: '{{ CUDNN_INSTALL_PATH }}'
    NCCL_INSTALL_PATH: '{{ NCCL_INSTALL_PATH }}'
    TF_CUDA_VERSION: '{{ cuda_version.stdout }}'
    TF_CUDNN_VERSION: '{{ cudnn_version.stdout }}'
    TF_DOWNLOAD_CLANG: '0'
    TF_ENABLE_XLA: '0'
    TF_NEED_COMPUTECPP: '0'
    TF_NEED_CUDA: '1'
    TF_NEED_MPI: '0'
    TF_NEED_OPENCL: '0'
    TF_NEED_OPENCL_SYCL: '0'
    TF_NEED_ROCM: '0'
    TF_NEED_TENSORRT: '0'
    TF_PYTHON_CONFIG_REPO: '@org_tensorflow//third_party/toolchains/cpus/py'
    TF_SET_ANDROID_WORKSPACE: '0'
    PYTHON_BIN_PATH: '{{ PYTHON_BIN_PATH }}'
    PYTHON_LIB_PATH: '{{ PYTHON_LIB_PATH }}'
    NUMPY_INCLUDE_DIR: '{{ NUMPY_INSTALL_DIR }}/lib64/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core/include/numpy'
    LD_LIBRARY_PATH: '{{ NUMPY_INSTALL_DIR }}/lib64/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core'
  register: tensorflow_configure_log_gpu
  when: USE_CPU == 'no' and USE_GPU == 'yes'

# Save CPU configure log (if we're using the CPU)
- local_action: template src=tensorflow_configure_log_cpu.j2 dest={{ TENSORFLOW_BUILD_DIR }}/configure.log
  when: USE_CPU == 'yes' and USE_GPU == 'no'

# Save GPU configure log (if we're using the GPU)
- local_action: template src=tensorflow_configure_log_gpu.j2 dest={{ TENSORFLOW_BUILD_DIR }}/configure.log
  when: USE_CPU == 'no' and USE_GPU == 'yes'

# Print out where the configure logs have been saved to
- debug:
    msg: "TensorFlow config logs saved to {{ TENSORFLOW_BUILD_DIR }}/configure.log"

# Now it's time to build TensorFlow for the CPU. We want to use the optimization flags that we
# found earlier, if applicable.
- name: Build TensorFlow for the CPU
  shell: |
    cd {{ TENSORFLOW_BUILD_DIR }}
    bazel build --copt=-mfpmath=both {{ ENABLE_AVX.stdout }} {{ ENABLE_AVX2.stdout }} {{ ENABLE_FMA.stdout }} {{ ENABLE_SSE2.stdout }} {{ ENABLE_SSE3.stdout }} {{ ENABLE_SSE4_1.stdout }} {{ ENABLE_SSE4_2.stdout }} -k //tensorflow/tools/pip_package:build_pip_package
  when: USE_CPU == 'yes' and USE_GPU == 'no'
  environment:
    LD_LIBRARY_PATH: '{{ NUMPY_INSTALL_DIR }}/lib64/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core'
  register: tensorflow_cpu_build_log

- local_action: template src=tensorflow_cpu_build_log.j2 dest={{ TENSORFLOW_BUILD_DIR }}/build.log
  when: USE_CPU == 'yes' and USE_GPU == 'no'

- name: Build TensorFlow for the GPU
  shell: |
    cd {{ TENSORFLOW_BUILD_DIR }}
    bazel build --copt=-mfpmath=both {{ ENABLE_AVX.stdout }} {{ ENABLE_AVX2.stdout }} {{ ENABLE_AVX512.stdout }} {{ ENABLE_FMA.stdout }} {{ ENABLE_SSE2.stdout }} {{ ENABLE_SSE3.stdout }} {{ ENABLE_SSE4_1.stdout }} {{ ENABLE_SSE4_2.stdout }}--config=cuda -k //tensorflow/tools/pip_package:build_pip_package
  when: USE_CPU == 'no' and USE_GPU == 'yes'
  environment:
    LD_LIBRARY_PATH: '{{ NUMPY_INSTALL_DIR }}/lib64/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core'
  register: tensorflow_gpu_build_log

- local_action: template src=tensorflow_gpu_build_log.j2 dest={{ TENSORFLOW_BUILD_DIR }}/build.log
  when: USE_CPU == 'no' and USE_GPU == 'yes'

- debug:
    msg: "TensorFlow build logs saved to {{ TENSORFLOW_BUILD_DIR }}/build.log"

- name: Build pip package with Bazel
  shell: |
    cd {{ TENSORFLOW_BUILD_DIR }}
    ./bazel-bin/tensorflow/tools/pip_package/build_pip_package {{ TF_PIP_PACKAGE_LOCATION }}
