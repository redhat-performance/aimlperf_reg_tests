---

# Before we gather information about AVX*, SSE*, FMA, etc. instructions, let's get the
# version of gcc
- name: Determine gcc version
  shell: '{{ CC }} --version | xargs | cut -d " " -f 3'
  register: GCC_VERSION

- name: Determine gcc main version
  shell: echo '{{ GCC_VERSION.stdout }}' | cut -d"." -f 1
  register: GCC_MAIN_VERSION

- name: Determine additional release info
  shell: echo '{{ GCC_VERSION.stdout }}' | cut -d"." -f 2
  register: GCC_RELEASE

# Next step is to determine if we have any AVX* instructions that we can take advantage of
- name: Determine if we have AVX instructions
  shell: |
    avx=$(lscpu | grep 'Flags' | grep avx)
    echo $avx
  register: HAVE_AVX

- name: Determine if we have AVX2 instructions
  shell: |
    avx2=$(lscpu | grep 'Flags' | grep avx2)
    echo $avx2
  register: HAVE_AVX2

# XXX:TODO --> Make check to see which version of gcc is being used. TensorFlow requires
# gcc version 4.9 or greater if using -mavx512f, -mavx512dq, etc.
- name: Determine if we have AVX512F instructions
  shell: |
    avx512f=$(lscpu | grep 'Flags' | grep avx512f)
    echo $avx512f
  register: HAVE_AVX512F

- name: Determine if we have AVX512DQ instructions
  shell: |
    avx512dq=$(lscpu | grep 'Flags' | grep avx512dq)
    echo $avx512dq
  register: HAVE_AVX512DQ

- name: Determine if we have AVX512CD instructions
  shell: |
    avx512cd=$(lscpu | grep 'Flags' | grep avx512cd)
    echo $avx512cd
  register: HAVE_AVX512CD

# Next step is to determine if we have FMA instructions that we can take advantage of
- name: Determine if we have FMA instructions
  shell: |
    fma=$(lscpu | grep 'Flags' | grep fma)
    echo $fma
  register: HAVE_FMA

# Now determine SSE* instructions
- name: Determine if we have SSE2 instructions
  shell: |
    sse2=$(lscpu | grep 'Flags' | grep sse2)
    echo $sse2
  register: HAVE_SSE2

- name: Determine if we have SSE3 instructions
  shell: |
    sse3=$(lscpu | grep 'Flags' | grep sse3)
    echo $sse3
  register: HAVE_SSE3

- name: Determine if we have SSE4.1 instructions
  shell: |
    sse4_1=$(lscpu | grep 'Flags' | grep sse4_1)
    echo $sse4_1
  register: HAVE_SSE4_1

- name: Determine if we have SSE4.2 instructions
  shell: |
    sse4_2=$(lscpu | grep 'Flags' | grep sse4_2)
    echo $sse4_2
  register: HAVE_SSE4_2

# Now that we've gathered information on optimization flags, let's set them appropriately
- name: Set AVX copt flag
  shell: if [[ ! -z '{{ HAVE_AVX.stdout }}' ]]; then echo "--copt=-mavx"; else echo ""; fi
  register: ENABLE_AVX

- name: Set AVX2 copt flag
  shell: if [[ ! -z '{{ HAVE_AVX2.stdout }}' ]]; then echo "--copt=-mavx2"; else echo ""; fi
  register: ENABLE_AVX2

- name: Set AVX512 copt flag
  shell: if (( '{{ GCC_MAIN_VERSION.stdout }}' < '{{ TENSORFLOW_AVX512_MIN_GCC_VER }}' )); then echo ""; elif (( '{{ GCC_RELEASE.stdout }}' < '{{ TENSORFLOW_AVX512_MIN_GCC_REL }}' )) && (( '{{ GCC_MAIN_VERSION.stdout }}' == '{{ TENSORFLOW_AVX512_MIN_GCC_VER }}' )); then echo ""; elif [[ ! -z '{{ HAVE_AVX512F.stdout }}' ]]; then echo "--copt=-mavx512f"; elif [[ ! -z '{{ HAVE_AVX512DQ.stdout }}' ]]; then echo "--copt=-mavx512dq"; elif [[ ! -z '{{ HAVE_AVX512CD.stdout }}' ]]; then echo "--copt=-mavx512cd"; else echo ""; fi
  register: ENABLE_AVX512

- name: Set FMA copt flag
  shell: if [[ ! -z '{{ HAVE_FMA.stdout }}' ]]; then echo "--copt=-mfma"; else echo ""; fi
  register: ENABLE_FMA

- name: Set SSE2 copt flag
  shell: if [[ ! -z '{{ HAVE_SSE2.stdout }}' ]]; then echo "--copt=-msse2"; else echo ""; fi
  register: ENABLE_SSE2

- name: Set SSE3 copt flag
  shell: if [[ ! -z '{{ HAVE_SSE3.stdout }}' ]]; then echo "--copt=-msse3"; else echo ""; fi
  register: ENABLE_SSE3

- name: Set SSE4.1 copt flag
  shell: if [[ ! -z '{{ HAVE_SSE4_1.stdout }}' ]]; then echo "--copt=-msse4.1"; else echo ""; fi
  register: ENABLE_SSE4_1

- name: Set SSE4.2 copt flag
  shell: if [[ ! -z '{{ HAVE_SSE4_2.stdout }}' ]]; then echo "--copt=-msse4.2"; else echo ""; fi
  register: ENABLE_SSE4_2

# Now let's print out our final compilation flags
- debug:
    msg: "Build flags: {{ ENABLE_AVX.stdout }} {{ ENABLE_AVX2.stdout }} {{ ENABLE_AVX512.stdout }} {{ ENABLE_FMA.stdout }} {{ ENABLE_SSE2.stdout }} {{ ENABLE_SSE3.stdout }} {{ ENABLE_SSE4_1.stdout }} {{ ENABLE_SSE4_2.stdout }}"

# Now configure TensorFlow for the CPU
- name: Configure TensorFlow for the CPU
  shell: |
    cd {{ TENSORFLOW_BUILD_DIR }} 
    ./configure
  environment:
    GCC_HOST_COMPILER_PATH: '{{ CC }}'
    CC_OPT_FLAGS: '-march=native'
    TF_DOWNLOAD_CLANG: '0'
    TF_ENABLE_XLA: '0'
    TF_NEED_COMPUTECPP: '0'
    TF_NEED_CUDA: '0'
    TF_NEED_MPI: '0'
    TF_NEED_OPENCL: '0'
    TF_NEED_OPENCL_SYCL: '0'
    TF_NEED_ROCM: '0'
    TF_NEED_TENSORRT: '0'
    TF_PYTHON_CONFIG_REPO: '@org_tensorflow//third_party/toolchains/cpus/py'
    TF_SET_ANDROID_WORKSPACE: '0'
    PYTHON_BIN_PATH: '{{ PYTHON_BIN_PATH }}'
    PYTHON_LIB_PATH: '{{ PYTHONPATH }}'
    NUMPY_INCLUDE_DIR: '{{ NUMPY_INSTALL_DIR }}/lib/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core/include/numpy'
    LD_LIBRARY_PATH: '{{ NUMPY_INSTALL_DIR }}/lib/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core:{{ GCC_LIBS }}'
  when: DEVICE == 'cpu'

- block:
  # Command taken from: https://georgesterpu.github.io/compile_tensorflow.html
  - name: If using the GPU, find the exact CUDA version
    shell: /usr/local/cuda/bin/nvcc --version | sed -n 's/^.*release \(.*\),.*/\1/p'
    register: cuda_version

  # Command taken from: https://georgesterpu.github.io/compile_tensorflow.html
  - name: If using the GPU, find cuDNN version
    shell: sed -n 's/^#define CUDNN_MAJOR\s*\(.*\).*/\1/p' /usr/local/cuda/include/cudnn.h
    register: cudnn_version

  # Grab the NCCL major version
  - name: If using the GPU, find NCCL major version
    shell: sed -n 's/^#define NCCL_MAJOR\s*\(.*\).*/\1/p' '{{ NCCL_INSTALL_PATH }}/include/nccl.h'
    register: nccl_major_version

  # Grab NCCL minor version
  - name: If using the GPU, find NCCL minor version
    shell: sed -n 's/^#define NCCL_MINOR\s*\(.*\).*/\1/p' '{{ NCCL_INSTALL_PATH }}/include/nccl.h'
    register: nccl_minor_version

  # Grab NCCL patch
  - name: If using the GPU, find NCCL patch
    shell: sed -n 's/^#define NCCL_PATCH\s*\(.*\).*/\1/p' '{{ NCCL_INSTALL_PATH }}/include/nccl.h'
    register: nccl_patch

  # Print out versions
  - debug:
      msg: 'CUDA version: {{ cuda_version.stdout }}'
  - debug:
      msg: 'cuDNN version: {{ cudnn_version.stdout }}'
  - debug:
      msg: 'NCCL version: {{ nccl_major_version.stdout }}.{{ nccl_minor_version.stdout }}.{{ nccl_patch.stdout }}'

  when: DEVICE == 'gpu'

# Get TensorRT version
- block:

  - name: If using the GPU and using TensorRT, find the TensorRT major version
    shell: sed -n 's/^#define NV_TENSORRT_MAJOR\s*\(.*\).*/\1/p' '{{ TENSORRT_INSTALL_PATH }}/include/NvInferVersion.h' | cut -d ' ' -f 1
    register: tensorrt_version

  - debug:
      msg: 'TensorRT version: {{ tensorrt_version.stdout }}'

  when: DEVICE == 'gpu' and USE_TENSORRT == 'yes'

# Now configure TensorFlow for the GPU
- name: Configure TensorFlow for the GPU w/o TensorRT
  shell: |
    cd {{ TENSORFLOW_BUILD_DIR }} 
    ./configure
  environment:
    GCC_HOST_COMPILER_PATH: '{{ CC }}'
    CC_OPT_FLAGS: '-march=native'
    TF_CUDA_PATHS: '/usr/local/cuda,/usr/include,{{ NCCL_INSTALL_PATH }}'
    TF_DOWNLOAD_CLANG: '0'
    TF_ENABLE_XLA: '0'
    TF_NEED_COMPUTECPP: '0'
    TF_NEED_CUDA: '1'
    TF_NEED_MPI: '0'
    TF_NEED_OPENCL: '0'
    TF_NEED_OPENCL_SYCL: '0'
    TF_NEED_ROCM: '0'
    TF_NEED_TENSORRT: '0'
    TF_PYTHON_CONFIG_REPO: '@org_tensorflow//third_party/toolchains/cpus/py'
    TF_SET_ANDROID_WORKSPACE: '0'
    PYTHON_BIN_PATH: '{{ PYTHON_BIN_PATH }}'
    PYTHON_LIB_PATH: '{{ PYTHONPATH }}'
    NUMPY_INCLUDE_DIR: '{{ NUMPY_INSTALL_DIR }}/lib/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core/include/numpy'
    LD_LIBRARY_PATH: '{{ NUMPY_INSTALL_DIR }}/lib/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core:{{ GCC_LIBS }}'
  when: DEVICE == 'gpu' and USE_TENSORRT == 'no'

# Now configure TensorFlow for the GPU
- name: Configure TensorFlow for the GPU w/ TensorRT
  shell: |
    cd {{ TENSORFLOW_BUILD_DIR }} 
    ./configure
  environment:
    GCC_HOST_COMPILER_PATH: '{{ CC }}'
    CC_OPT_FLAGS: '-march=native'
    TF_CUDA_PATHS: '/usr/local/cuda,/usr/include,{{ NCCL_INSTALL_PATH }},{{ TENSORRT_INSTALL_PATH }}'
    TF_CUDA_VERSION: '{{ cuda_version.stdout }}'
    TF_CUDNN_VERSION: '{{ cudnn_version.stdout }}'
    TF_DOWNLOAD_CLANG: '0'
    TF_ENABLE_XLA: '0'
    TF_NCCL_VERSION: '{{ nccl_major_version.stdout }}'
    TF_NEED_COMPUTECPP: '0'
    TF_NEED_CUDA: '1'
    TF_NEED_MPI: '0'
    TF_NEED_OPENCL: '0'
    TF_NEED_OPENCL_SYCL: '0'
    TF_NEED_ROCM: '0'
    TF_NEED_TENSORRT: '1'
    TF_PYTHON_CONFIG_REPO: '@org_tensorflow//third_party/toolchains/cpus/py'
    TF_SET_ANDROID_WORKSPACE: '0'
    TF_TENSORRT_VERSION: '{{ tensorrt_version.stdout }}'
    PYTHON_BIN_PATH: '{{ PYTHON_BIN_PATH }}'
    PYTHON_LIB_PATH: '{{ PYTHONPATH }}'
    NUMPY_INCLUDE_DIR: '{{ NUMPY_INSTALL_DIR }}/lib/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core/include/numpy'
    LD_LIBRARY_PATH: '{{ NUMPY_INSTALL_DIR }}/lib/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core:{{ GCC_LIBS }}'
  when: DEVICE == 'gpu' and USE_TENSORRT == 'yes'

# Print out where the configure logs have been saved to
- debug:
    msg: "TensorFlow config logs saved to {{ TENSORFLOW_BUILD_DIR }}/configure.log"

# Update 'WORKSPACE'
- name: Workaround --> update {{ TENSORFLOW_BUILD_DIR }}/WORKSPACE to add the 'io_bazel_rules_docker' http archive so that bazel rules can be cloned
  blockinfile:
    path: '{{ TENSORFLOW_BUILD_DIR }}/WORKSPACE'
    insertafter: 'load\(\"\@bazel\_tools\/\/tools\/build\_defs\/repo:http.bzl\",\ \"http_archive\",\ \"http_file"\)'
    block: |
      http_archive(
          name = "io_bazel_rules_docker",
          sha256 = "aed1c249d4ec8f703edddf35cbe9dfaca0b5f5ea6e4cd9e83e99f3b0d1136c3d",
          strip_prefix = "rules_docker-0.7.0",
          urls = ["https://github.com/bazelbuild/rules_docker/archive/v0.7.0.tar.gz"],
      )

# Now it's time to build TensorFlow for the CPU. We want to use the optimization flags that we
# found earlier, if applicable.
- name: Build TensorFlow for the CPU
  shell: |
    cd {{ TENSORFLOW_BUILD_DIR }}
    bazel build --copt=-mfpmath=both {{ ENABLE_AVX.stdout }} {{ ENABLE_AVX2.stdout }} {{ ENABLE_AVX512.stdout }} {{ ENABLE_FMA.stdout }} {{ ENABLE_SSE2.stdout }} {{ ENABLE_SSE3.stdout }} {{ ENABLE_SSE4_1.stdout }} {{ ENABLE_SSE4_2.stdout }} --config=opt -k //tensorflow/tools/pip_package:build_pip_package
  when: DEVICE == 'cpu'
  environment:
    LD_LIBRARY_PATH: '{{ NUMPY_INSTALL_DIR }}/lib/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core:{{ GCC_LIBS }}'

- name: Build TensorFlow for the GPU
  shell: |
    cd {{ TENSORFLOW_BUILD_DIR }}
    bazel build --copt="-I/usr/include" --copt=-mfpmath=both {{ ENABLE_AVX.stdout }} {{ ENABLE_AVX2.stdout }} {{ ENABLE_AVX512.stdout }} {{ ENABLE_FMA.stdout }} {{ ENABLE_SSE2.stdout }} {{ ENABLE_SSE3.stdout }} {{ ENABLE_SSE4_1.stdout }} {{ ENABLE_SSE4_2.stdout }} --config=opt --config=cuda -k //tensorflow/tools/pip_package:build_pip_package
  when: DEVICE == 'gpu'
  environment:
    LD_LIBRARY_PATH: '{{ NUMPY_INSTALL_DIR }}/lib/python3.6/site-packages/numpy-{{ NUMPY_VERSION }}-py3.6-linux-x86_64.egg/numpy/core:{{ GCC_LIBS }}'
    TMP: '/tmp'
    TF_CUDA_PATHS: '/usr/local/cuda,/usr/include,{{ NCCL_INSTALL_PATH }},{{ TENSORRT_INSTALL_PATH }}'

- debug:
    msg: "TensorFlow build logs saved to {{ TENSORFLOW_BUILD_DIR }}/build.log"

- name: Build pip package with Bazel
  shell: |
    cd {{ TENSORFLOW_BUILD_DIR }}
    ./bazel-bin/tensorflow/tools/pip_package/build_pip_package {{ TF_PIP_PACKAGE_LOCATION }}
