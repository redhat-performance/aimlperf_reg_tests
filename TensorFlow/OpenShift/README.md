# OpenShift Files

## Overview

This folder contains files used for launching the [official TensorFlow High-Performance CNN benchmarks](https://github.com/tensorflow/benchmarks/tree/master/scripts/tf_cnn_benchmarks) as an app in OpenShift on AWS. If you wish to build and run TensorFlow on RHEL 8, follow the instructions in the next section carefully. They are required. Otherwise, for RHEL 7 builds, you can skip to the **Basics** section.

## PREP WORK

### 1. Configure

The entire image build, s2i app build, benchmarks, etc. process is streamlined with a Makefile that is generated by the `configure` script in this directory. Before you do anything, run:

```
$ ./configure <flags>
```

For help on using `configure`, run:

```
$ ./configure --help
```

If you use the `--instance-type`/`-t` flag when configuring the Makefile and specify an instance that does not exist yet (which is perfectly okay!), you will need to setup an instance before executing the `make` commands. Information on how to setup an instance using `MachineSet` will be described later on, but do not worry about that yet. For now, follow the instructions in the next subsection, which describes how to install the necessary cluster operators for running the benchmarks.

### 2. Installing Necessary Cluster Operators

After you've run `configure`, you should setup and install three necessary operators to your cluster: Special Resource Operator (SRO), Node Feature Discovery (NFD) Operator, and Ripsaw. If you haven't installed *any* of these operators, run

```
$ make setup_operators
```

The SRO is used for installing NVIDIA drivers to your cluster, the NFD operator is used for discovering node features, and Ripsaw is for running the benchmarks.

If you have installed one or more of these operators already, you can run one or more of these commands to install specific operators:

```
$ make setup_gpu     #sets up SRO
$ make setup_nfd     #sets up the NFD operator
$ make setup_ripsaw  #sets up the Ripsaw operator
```

Once you've installed the necessary operators, you should follow the next two subsections for creating 'base images' using registry.redhat.io images. (Note: these sections only apply if you are using RHEL 7 CUDA builds or non-CUDA RHEL 8 builds.)

### 3. Using registry.redhat.io Images (REQUIRED FOR CUDA RHEL 7 BUILDS + NON-CUDA RHEL 8 BUILDS)

Follow the instructions in the `setup` folder in this directory. In essence, you will need to run a create two files under **../../secrets**, then run a `make` command.

### 4. Building and Using a CUDA "Base Image" from this Repository

To prepare for a CUDA build using a "base image," make sure to build one of the Docker images under `../Dockerfiles/custom/rhel7/cuda` or `../Dockerfiles/custom/rhel8/cuda`. Follow the instructions in the **setup** folder in this directory to do so. Such base images have cuDNN and NCCL pre-installed, which means you can skip the next subsection "Setting up an EBS Volume." Otherwise, for images that do *not* have cuDNN and NCCL pre-installed, you will need to setup an EBS volume that contains such packages by following the instructions below.

### 5. Setting up an EBS Volume (for Non Custom Base Images)

To prepare for CUDA builds in images which do *not* have cuDNN and NCCL preinstalled, you will first need to create an EBS volume, like so:

```
$ cd setup/volumes
$ sh create_ebs_volume.sh -n <volume_name> -t <volume_type> -s <volume_size> -z <aws_availability_zone>
```

Once you've created your volume, create a dummy pod that will be used for storing data in the EBS storage via a PV (Persistent Volume):

```
$ #cd setup/volumes
$ sh create_temp_nvidia_pod.sh <volume_id>
```

This will create a temporary pod named `tmp-nvidia-pod`, which you can access by executing:

```
$ oc exec -it tmp-nvidia-pod -- /bin/bash
```

The EBS volume will be mounted under `/tmp/nvidia_ebs`. From there, you can download your two (required) NVIDIA packages: (1.) NCCL, and (2.) cuDNN.

If you have an s3 bucket where the packages are stored, then install `awscli` via `pip` or `pip3`, configure it to provide your credentials, and download. Otherwise, download from wherever you have your tarballs hosted.

Once you're done, type `exit` to exit the pod. Because you won't be needing it anymore, you can delete it via:

```
$ oc delete pod/tmp-nvidia-pod
```

Now you're all set! The EBS volume should have your cuDNN and NCCL tar files!

#### Warning About Using ubi8 and Related Images

The RHEL 8 "ubi8" image has a limited set of packages that can be installed through its included repos. Even NVIDIA's `nvidia/cuda:<tag>` images reference ubi8, so the same issue lies there. Thus, in order to obtain the packages that *cannot* be installed through those repos, you will need to create your own image using one of the custom provided Dockerfiles in `../Dockerfiles/custom` and supply your own `.repo` files to point to RHEL 8 repositories.

## Preparing ImageNet

If you would like to use real ImageNet data, please follow the instructions in **setup/README.md** for ImageNet. This process requires using an EBS volume to 'host' your ImageNet data. It is very similar to the approach of creating a temporary NVIDIA pod for holding NVIDIA packages.

To create an ImageNet EBS volume,

```
$ cd setup/volumes
$ sh create_ebs_volume.sh -n <volume_name> -t <volume_type> -s <volume_size> -z <aws_availability_zone>
```

Once you've created your volume, create a dummy pod that will be used for storing data in the EBS storage via a PV (Persistent Volume):

```
$ #cd setup/volumes
$ sh create_temp_imagenet_pod.sh <volume_id>
```

From here, enter the pod via 

```
oc exec -it tmp-imagenet-pod -- /bin/bash
```

...then download/upload your ImageNet data to the mounted volume located at `/tmp/imagenet_ebs`. Delete the pod when you're done, if desired.

## How to Run the Benchmarks

### Optional Prerequisites

Assuming you have already run `configure` to generate a Makefile, your next steps depend on whether or not you have requested (via `configure`) to use a specific instance type or an instance with specific attributes. If you do want to use a specific instance or specific type of instance, follow the next subsection. Otherwise, you may skip said subsection and move on to **Advanced CPU Options** if you wish to use CPU Manager. You can skip that section too, though, if you are using GPUs or do not want to use CPU Manager.

#### Automatically creating a Node

If you wish to create a MachineSet and run the pod on a node with a specific instance type, use `../../helper_scripts/OpenShift/create_machineset.sh` to create a YAML file. Or you can create your own YAML file. The script is provided as a convenience.

Once your YAML file has been generated,

```
$ oc create -f <YAML_filename>
```

If you would like information on how to use the script,

```
$ sh ../../create_machineset.sh -h
```

To get your AMI ID and cluster ID, either log into your [AWS console](https://aws.amazon.com/console/) and find your cluster, **or** 

```
$ aws iam list-instance-profiles --output json | grep <your_cluster_name_or_partial_cluster_name> -B 18
            "InstanceProfileId": "<instance_profile_id>", 
            "Roles": [
                {
                    "AssumeRolePolicyDocument": {
                        "Version": "2012-10-17", 
                        "Statement": [
                            {
                                "Action": "sts:AssumeRole", 
                                "Principal": {
                                    "Service": "ec2.amazonaws.com"
                                }, 
                                "Effect": "Allow", 
                                "Sid": ""
                            }
                        ]
                    }, 
                    "RoleId": "<role_id>", 
                    "CreateDate": "2019-07-18T15:57:33Z", 
                    "RoleName": "<cluster_id>-worker-role", 
                    "Path": "/", 
                    "Arn": "arn:aws:iam:<id>:role/<cluster_id>-worker-role"
                }
            ], 
            "CreateDate": "2019-07-18T15:57:33Z", 
            "InstanceProfileName": "<cluster_id>-worker-profile", 
            "Path": "/", 
            "Arn": "arn:aws:iam::<id>:instance-profile/<cluster_id>-worker-profile"

$ aws ec2 describe-instances --filters "Name=iam-instance-profile.id,Values=<instance_profile_id>" --output json | grep ImageId
                    "ImageId": "ami-<hash>", 
                    "ImageId": "ami-<hash>", 
                    "ImageId": "ami-<hash>", 
```

#### Advanced CPU Options (CPU Manager)

CPU Manager info: https://docs.openshift.com/container-platform/4.1/scalability_and_performance/using-cpu-manager.html

##### Installing and Enabling CPU Manager

First, install and enable CPU Manager to your cluster. To do so,

```
$ sh ../../helper_scripts/OpenShift/enable_cpumanager.sh -n <node_name> -k /path/to/cpumanager-kubeletconfig.yaml -x <avx_instruction_set>
```

or

```
$ sh ../../helper_scripts/OpenShift/enable_cpumanager.sh -n <node_name> -k /path/to/cpumanager-kubeletconfig.yaml -i <instance_type>
```

##### Uninstalling and Disabling CPU Manager

To uninstall,

```
$ sh ../../helper_scripts/OpenShift/disable_cpumanager.sh -n <node_name> -k /path/to/cpumanager-kubeletconfig.yaml -x <avx_instruction_set>
```

or

```
$ sh ../../helper_scripts/OpenShift/disable_cpumanager.sh -n <node_name> -k /path/to/cpumanager-kubeletconfig.yaml -i <instance_type>
```

### Basics

Now you're ready to build the necessary images to run the benchmarks. You can do everything at once by running:

```
$ make
``

This command will build a "base" imagestream that is used by a Source-to-Image (s2i) strategy that generates an image from the scripts under `../.s2i_fftw` or `../.s2i_openblas`. Once the s2i image has been built, the benchmarks are executed using [Ripsaw](https://github.com/cloud-bulldozer/ripsaw).

To build just the base imagestream,

```
$ make imagestream
```

To build just the s2i imagestream,

```
$ make s2i
```

To run just the benchmarks,

```
$ make benchmarks
```

As the build commands execute, they will call scripts from the `scripts` folder in this directory. These scripts let you know the status of the build by checking every 10 seconds to see if the build is pending, has succeeded, or has failed. **Do not exit out of these scripts.**  Once the scripts complete, the next `make` command will execute. Or if you are building everything step by step (e.g., `make imagestream`, `make s2i`, etc.), either wait until the referenced script finishes executing before calling your next `make` command, or wait until the build has completed by checking `oc status`.

Note that if you *must* prematurely stop `make imagestream` or `make s2i`, you must run `make clean_imagestream` (if you prematurely stopped `make imagestream`) or `make clean_s2i` (if you prematurely stopped `make s2i`) before running them again. Also, note that even if you *do* run the "clean" commands, your next `make imagestream` or `make s2i` command will likely fail, with an error saying "Image build has STOPPED." This is expected with OpenShift 4.x. To rectify this behavior, simply rerun the `make clean_imagestream` or `make clean_s2i` command (depending on which command failed), followed by `make imagestream` or `make s2i`.

